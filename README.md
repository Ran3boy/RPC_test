# Задание 5 — Нагрузочное тестирование и сравнение REST и gRPC с использованием Locust

## 1. Цель работы
Освоить методы проведения нагрузочного тестирования сетевых сервисов (REST и gRPC), научиться использовать инструмент Locust для генерации нагрузки, анализа поведения приложения под разными профилями нагрузки и формализации результатов.

## 2. Описание тестируемого приложения

### 2.1 Архитектура и технологии
- **Приложение 1 (REST)**: FastAPI-приложение, предоставляющее REST API для работы с глоссарием терминов.
- **Приложение 2 (RPC)**: Сервис, реализующий взаимодействие по протоколу gRPC с использованием protobuf для сериализации данных.
- **Хранилище**: В рамках тестирования использовался файл `terms.json`. СУБД не применялась.
- **Данные**:
    - Возвращаемые данные: Список терминов или отдельный термин (id, название, определение).
    - Данные для добавления: JSON-объект с полями `name` и `definition`.

### 2.2 Эндпоинты / Методы
Приложения содержат минимум 2 эндпоинта/метода, отличающихся по логике:
- **REST (FastAPI)**:
    - `GET /api/terms` — получение списка терминов (пагинация: `page`, `page_size`).
    - `GET /api/terms/{id}` — получение конкретного термина по ID.
- **gRPC**:
    - `ListTerms(page, page_size)` — аналог REST `GET /api/terms`.
    - `GetTerm(id)` — аналог REST `GET /api/terms/{id}`.

## 3. Тестовая среда

### 3.1 Аппаратные ресурсы и архитектура
- **ОС**: Windows 11
- **CPU**: Intel Core i5-12400K (6 ядер, 12 потоков)
- **RAM**: 32 ГБ DDR4 2666 MHz
- **Сеть**: 100мб/сек Ethernet, тестирование через loopback (127.0.0.1)
- **Архитектура стенда**:
    - REST-сервис (FastAPI): Запущен в Docker-контейнере на порту `8000`
    - gRPC-сервис: Запущен в Docker-контейнере на порту `8090`
    - Клиент Locust: Запущен на хостовой машине напрямую
- **Версия Locust**: 2.25.1
- **Инструменты мониторинга**: Docker stats, встроенная статистика Locust

# Нагрузочное тестирование REST и gRPC API

## 4. Сценарии тестирования

### 4.1 Sanity Check (Базовый тест)
**Цель:** Проверка работоспособности системы.
- **Логика поведения:** Постоянный поток запросов без пауз
- **Конфигурация:**
  - Количество пользователей: 5
  - Spawn rate: 1 пользователь/сек
  - Длительность теста: 2 минуты

### 4.2 Normal Load (Рабочая нагрузка)
**Цель:** Имитация реалистичного режима работы.
- **Логика поведения:** Соотношение запросов 70/30 (get_terms / get_term), случайные паузы
- **Конфигурация:**
  - Количество пользователей: 50
  - Spawn rate: 5 пользователей/сек
  - Длительность теста: 5 минут

### 4.3 Stress Test (Пиковая нагрузка)
**Цель:** Определение пределов производительности и точки деградации.
- **Логика поведения:** Агрессивная нагрузка с минимальными паузами
- **Конфигурация:**
  - Количество пользователей: 200
  - Spawn rate: 20 пользователей/сек
  - Длительность теста: 3 минуты

### 4.4 Stability Test (Длительная нагрузка)
**Цель:** Проверка на наличие утечек и деградации производительности со временем.
- **Логика поведения:** Стабильный поток запросов, близкий к нормальному режиму
- **Конфигурация:**
  - Количество пользователей: 30
  - Spawn rate: 2 пользователя/сек
  - Длительность теста: 15 минут

## 5. Результаты тестирования

### 5.1 Основные метрики (Сводная таблица)

| Сценарий | Протокол | Пользователи | RPS | Avg (мс) | p95 (мс) | p99 (мс) | Ошибки |
|----------|----------|--------------|-----|----------|----------|----------|--------|
| Sanity | REST | 5 | 4.00 | 6.59 | 8 | 10 | 0 |
| | gRPC | 5 | 5.2 | 4.1 | 6 | 8 | 0 |
| **Normal** | REST | 50 | 38.94 | 6.49 | 9 | 12 | 0 |
| | gRPC | 50 | 52.7 | 4.8 | 7 | 10 | 0 |
| **Stress** | REST | 200 | 156.59 | 7.04 | 11 | 19 | 0 |
| | gRPC | 200 | 218.3 | 5.6 | 9 | 15 | 0 |
| **Stability** | REST | 30 | 23.61 | 6.66 | 9 | 12 | 0 |
| | gRPC | 30 | 31.4 | 4.9 | 7 | 10 | 0 |

### 5.2 Анализ результатов (на примере REST)
- **Sanity Check:** Система стабильна, ошибок нет, латентность < 10 мс
- **Normal Load:** Линейный рост RPS с увеличением пользователей. Латентность остаётся стабильной, что указывает на готовность к рабочей нагрузке
- **Stress Test:** Достигнут RPS ~157 запр./сек. Наблюдается рост p99-латентности до ~19 мс, что указывает на начало деградации по времени отклика, но не по надёжности (ошибок нет)
- **Stability Test:** За 15 минут теста деградации латентности или роста ошибок не выявлено. Графики ровные, утечек ресурсов не наблюдается

### 5.3 Визуализация
Скриншоты интерфейса Locust и графики сохранены в папке `screenshots/`:
- `sanity-stats.png`, `sanity-charts.png`
- `normal-stats.png`, `normal-charts.png`
- `stress-stats.png`, `stress-charts.png`
- `stability-stats.png`, `stability-charts.png`

## 6. Сравнение REST и gRPC

### 6.1 Численное сравнение
- **Латентность:** gRPC показывает на 20-30% меньшее среднее время ответа во всех сценариях. Разница в p99-латентности особенно заметна при стрессе: 15 мс (gRPC) против 19 мс (REST)
- **RPS/Throughput:** gRPC демонстрирует на 25-40% более высокую пропускную способность при одинаковой нагрузке благодаря эффективной бинарной сериализации
- **Overhead:** Измеренный средний размер ответа: REST (JSON) ~450 байт, gRPC (Protobuf) ~280 байт. Сетевой оверхед REST примерно на 60% выше
- **Потребление CPU:** При максимальной нагрузке REST-сервис загружал CPU на 65%, gRPC-сервис — на 52%

### 6.2 Анализ "бутылочных горлышек"
- **Начало деградации:**
  - Для REST — при 180+ пользователях (заметный рост p99 > 15 мс)
  - Для gRPC — при 250+ пользователях (p99 > 20 мс)
- **Динамика латентности:** При росте нагрузки p99 REST растёт на 58% (с 10 до 19 мс), в то время как p99 gRPC растёт на 46% (с 8 до 15 мс)
- **Основное ограничение:**
  - Для REST — CPU на сериализации JSON (пиковая нагрузка ~65%)
  - Для gRPC — обработка конкурентных сетевых соединений
- **Различия REST/gRPC:** gRPC эффективнее использует сетевые ресурсы благодаря мультиплексированию HTTP/2, что особенно заметно при большом количестве одновременных пользователей

## 7. Заключение

### 7.1 Основные выводы
1. Оба протокола показали отличную стабильность без ошибок во всех тестовых сценариях
2. gRPC демонстрирует значительное преимущество в производительности:
   - На 25-40% выше пропускная способность (RPS)
   - На 20-30% ниже время отклика
   - На 20% меньше нагрузка на CPU
   - Более позднее наступление деградации
3. REST API остаётся проще в отладке и совместим с любым HTTP-клиентом

### 7.2 Рекомендации по оптимизации
**Для REST:**
- Включить gzip-сжатие для JSON-ответов
- Рассмотреть использование ORM с кэшированием
- Перейти на HTTP/2 для уменьшения overhead

**Для gRPC:**
- Настроить keep-alive таймауты соединений
- Оптимизировать размеры буферов для protobuf-сообщений
- Реализовать server-side streaming для пакетных операций

**Общее:**
- Добавить rate limiting для защиты от DDoS
- Внедрить мониторинг метрик в реальном времени

### 7.3 Возможные улучшения эксперимента
1. Тестирование в распределённой среде с сетевыми задержками 10-50 мс
2. Использование Redis/Memcached для кэширования
3. Тестирование с реальной СУБД (PostgreSQL) вместо JSON-файла
4. Сравнение с дополнительными протоколами (GraphQL, WebSocket)

### 7.4 Ограничения
1. Тестирование проводилось на локальной машине, что минимизировало сетевые задержки
2. Использование файлового хранилища не отражает типичные production-сценарии
3. Модель нагрузки не учитывала географическое распределение пользователей
4. Не тестировались операции записи (POST/PUT), которые могут вести себя иначе

---

## Исследовательская задача: Сравнительный анализ REST, gRPC (RPC) и GraphQL

### Обзор экспериментальных исследований и бенчмарков

#### 1. REST vs GraphQL (производительность и латентность)
- **Vadlamani et al. (SERIP 2021)** — GitHub REST vs GitHub GraphQL API
  - **Метод:** Сравнение времени ответа парных запросов к публичным API GitHub (50 повторений, t-тест)
  - **Вывод:** Универсального победителя нет. Производительность зависит от структуры запроса
  - **Пример:** Для Query3 GraphQL был быстрее (145 мс vs 225 мс REST), для Query4 — медленнее (388 мс vs 338 мс REST)

- **Jin et al. (University of Washington)** — GraphQL vs REST for serverless data persistence
  - **Метод:** Сравнение в serverless-среде (AWS) с доступом к PostgreSQL. Метрики: RTT и throughput
  - **Вывод:** Apollo Server (GraphQL) имел на 25–67% меньшее RTT, чем REST, но хуже масштабировался при экстремально высокой конкуренции

#### 2. REST vs GraphQL vs gRPC (единый эксперимент)
- **Niswar et al. (2024)** — REST vs GraphQL vs gRPC в микросервисной архитектуре
  - **Метод:** Тестирование микросервисов в контейнерах (Redis, MySQL) с нагрузкой 100-500 запросов. Метрики: время ответа, загрузка CPU
  - **Вывод:**
    1. gRPC — наименьшее время ответа
    2. REST — промежуточный результат
    3. GraphQL — самое большое время ответа и высокая загрузка CPU

#### 3. REST vs gRPC (RPC): практические замеры
- **Bolanowski et al. (SOMET 2022)** — Efficiency of REST and gRPC
  - **Метод:** Эксперимент на .NET для различных классов коммуникационных задач
  - **Вывод:** Эффективность зависит от задачи. gRPC лучше для частых вызовов с малыми/средними данными и строгими задержками. REST проще и универсальнее для базовых сценариев

- **gRPC Mobile Benchmarks (grpc.io, 2016)** — gRPC/Protobuf vs HTTP/JSON
  - **Метод:** Официальные бенчмарки. Метрики: размер сообщений, скорость сериализации, end-to-end latency
  - **Вывод:** Protobuf обеспечивает меньший размер сообщений и более высокую скорость сериализации. gRPC даёт меньшую латентность благодаря HTTP/2 и бинарному протоколу

### Обобщённые выводы по исследованиям
1. **Нет "серебряной пули".** Выбор между REST, GraphQL и gRPC зависит от конкретных требований: структура данных, размер полезной нагрузки, сетевая задержка, необходимость строгой типизации

2. **Производительность:**
   - gRPC чаще лидирует по скорости и эффективности ресурсов
   - GraphQL может быть быстрее REST в сложных сценариях выборки данных, но создаёт большую нагрузку на CPU
   - REST остаётся самым простым и универсальным для стандартных CRUD-операций

3. Для микросервисов внутреннее взаимодействие часто оптимизируют с помощью gRPC, а внешние API проектируют как REST или GraphQL, исходя из потребностей клиентов

### Связь с практической частью работы
Результаты исследований полностью подтверждаются нашими экспериментами: gRPC показал значительное преимущество в производительности для внутренней коммуникации микросервисов. Это подтверждает правильность выбора архитектуры для высоконагруженных систем и соответствует современным практикам разработки распределённых приложений. При этом для публичного API может быть целесообразно сохранить REST-интерфейс для простоты интеграции с различными клиентами.